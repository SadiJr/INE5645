\section{\normalsize MPI (\textit{MESSAGE PASSING INTERFACE})}\label{mpi}
	O  MPI é um padrão de interface voltado para a troca de mensagens em máquinas paralelas com memória distribuída. Apesar de alguns pensarem dessa forma, o MPI não é um compilador ou um produto específico. Além disso, o MPI também fornece suporte à troca de mensagens entre máquinas com memória compartilhada.
	
	No padrão MPI, uma aplicação é constituída por um ou mais processos que se comunicam através da invocação de funções para o envio e recebimento de mensagens entre si. Inicialmente, na maioria das implementações, um conjunto fixo de processos é criado. Porém, esses processos podem executar diferentes programas. Por isso, o padrão MPI é algumas vezes referido como MPMD (\textit{Multiple Program Multiple Data}).

	Elementos importantes em implementações paralelas são a comunicação de dados entre processos paralelos e o balanceamento da carga. É importante frisar que o número de processos no MPI normalmente é fixo. Dito isso, tais processos podem usar mecanismos de comunicação ponto a ponto (operações para enviar mensagens de um determinado processo a outro), ou coletivas, na qual um grupo de processos pode invocar operações coletivas de comunicação para executar operações globais. 

	Sobre o MPI, o mesmo é capaz de suportar comunicação assíncrona e programação modular, através de mecanismos de comunicadores que permitem ao usuário MPI definir módulos que encapsulem estruturas de comunicação interna.

	Finalmente, os algoritmos que criam um processo para cada processador podem ser implementados, diretamente, utilizando-se comunicação ponto a ponto ou coletivas, sendo que os algoritmos que implementam a criação de tarefas dinâmicas ou que garantem a execução concorrente de muitas tarefas, num único processador, precisam de um refinamento nas implementações com o MPI.
	
	Com relação à sua real implementação em um programa, a mesma só é possível através do uso de bibliotecas\footnote{sendo as principais o MPICH(\url{https://www.mpich.org/}) e o Open MPI(\url{https://www.open-mpi.org/})} que fornecem implementações das funções do padrão MPI. É importante salientar que apesar de seguirem a especificação, tais bibliotecas podem diferir em uso e desempenho.

	\subsection{\normalsize FUNÇÕES USADAS}\label{mpi}
		O MPI apresenta uma grande gama de funções que implementam diferentes formas de envio de mensagens entre processos. Dito isso, apenas duas dessas funções\footnote{aqui não está sendo considerado as funções de inicialização do MPI, vide:\\
		MPI\_Init (\&argc, \&argv);\\
		MPI\_Comm\_size (comm, \&size) e\\
		MPI\_Comm\_rank (comm, \&rank)} foram utilizadas neste trabalho, melhor detalhadas nas subsubseções abaixo.
		
		\subsubsection{\normalsize \textit{MPI\_Send(void* data, int count, MPI\_Datatype datatype, int destination, int tag, MPI\_Comm communicator)}}\label{send}
			Função responsável por enviar mensagens de um processo para outro. Possuí os parâmetros:
			\begin{itemize}
				\item \textit{void* data}:\\
					É um ponteiro para o dado que será enviado.
				
				\item \textit{int count}:\\
					O tamanho total que será enviado.
					
				\item \textit{MPI\_Datatype datatype}:\\
					O tipo de dado que será enviado, podendo ser:
					\begin{itemize}
						\item MPI\_SHORT;
						\item MPI\_INT;
						\item MPI\_LONG;
						\item MPI\_LONG\_LONG;
						\item MPI\_UNSIGNED\_CHAR;
						\item MPI\_UNSIGNED\_SHORT;
						\item MPI\_UNSIGNED;
						\item MPI\_UNSIGNED\_LONG;
						\item MPI\_UNSIGNED\_LONG\_LONG;
						\item MPI\_FLOAT;
						\item MPI\_DOUBLE;
						\item MPI\_LONG\_DOUBLE e
						\item MPI\_BYTE.
					\end{itemize}
					Trata-se de um constante da própria especificação, usada para evitar incompatibilidade no tamanho dos tipos entre diferentes plataformas.
					
				\item \textit{int destination}:\\
					Identificador do processo para o qual a mensagem será enviada.
										
				\item \textit{int tag}:\\
					Variável personalizável, podendo ser usada para, de acordo com o valor, implementar diferentes ações no receptor. Uma questão importante é que a mensagem só será recepcionada se o valor da \textit{tag} for o mesmo no emissor e no receptor da mensagem.
					
				\item \textit{MPI\_Comm communicator}:\\
							Identifica um grupo específico de processos para o qual a mensagem será enviada.	
			\end{itemize}
			
		\subsubsection{\normalsize \textit{MPI\_Recv(void* data, int count, MPI\_Datatype datatype, int source, int tag, MPI\_Comm communicator, MPI\_Status* status)}}\label{recv}
			Função responsável pelo recebimento de mensagens. Possuí os parâmetros:
			\begin{itemize}
				\item \textit{void* data}:\\
					É um ponteiro que indica o local de memória no qual a mensagem recebida será armazenada.
				
				\item \textit{int count}:\\
					Variável que pode ser utilizada para armazenar o tamanho do dado recebido, ou para indicar o tamanho total que se espera receber.
					
				\item \textit{MPI\_Datatype datatype}:\\
					Equivalente ao do \textit{MPI\_Send}.
					
				\item \textit{int destination}:\\
					Identificador do processo do qual se espera receber uma mensagem.
										
				\item \textit{int tag}:\\
					Equivalente ao do \textit{MPI\_Send}.
					
				\item \textit{MPI\_Comm communicator}:\\
					Equivalente ao do \textit{MPI\_Send}.
				
				\item \textit{MPI\_Status* status}:\\
					É uma estrutura que armazena detalhes da transmissão da mensagem.
			\end{itemize}
			