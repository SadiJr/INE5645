\section{\normalsize CONCLUSÕES}
	Como era de se esperar, a implementação paralela só obteve melhor desempenho sobre a sequencial quando o tamanho do vetor era relativamente grande, o que confirma que o processamento paralelo de dados só é vantajoso quando existe uma quantidade absurda de dados para serem processados. 
	
	Além disso, pode-se observar que esse algoritmo não possibilita \textit{speedup} linear, uma vez que, dependendo do tamanho do vetor, acrescentar mais processos acarreta em perda de desempenho. Isso pode ser facilmente observável nos vetores de tamanho 1000000000 e 2147483647, onde, ao utilizar mais de 6 processos, se obteve uma perda de desempenho considerável.
	
	Fora isso, em todas as execuções foi comprovado que a implementação que se utiliza da estratégia de alocação de \textit{buckets} sem gerência precisa de memória, melhor explicada na seção \ref{personal}, possuí desempenho superior ao da implementação com alocação exata de \textit{buckets}. Em compensação, foi comprovado que a implementação que utiliza a estratégia com melhor gerência de memória é capaz de processar uma quantidade maior de dados sem resultar em estouros de memória ou travamento da máquina, cenário não tão incomum para a outra solução.
	
	Para maiores informações a respeito dos resultados obtidos, favor ler os \textit{logs} das aplicações, que se encontram no arquivo anexado.